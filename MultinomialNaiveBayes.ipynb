{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing comment verification/spam detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and utility functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from PersianStemmer import PersianStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text=str(text)\n",
    "    import string\n",
    "    punct = string.punctuation + '.،!\"#$%&|×/:؛,][\\}{«»<>؟'\n",
    "\n",
    "    return text.translate({ord(p): \" \" for p in punct})\n",
    "\n",
    "def stopwords(text):\n",
    "    text = [word for word in text.split() if word not in sw]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_enter (comment):\n",
    "    comment =re.sub(r'[(\\r\\n)+]|[\\r\\n]+', ' ', comment)\n",
    "    comment =re.sub(r'\\s+', ' ', comment)\n",
    "    return comment\n",
    "\n",
    "def stemmingText (arr):\n",
    "    for i,val in enumerate(arr):\n",
    "        arr[i] = ps.run(val)\n",
    "    return (\" \".join(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions for calculating probabilities consist of simple probability and conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_prob (word, label):\n",
    "    if label==0:\n",
    "        return (not_spam_dic[word]+1)/(word_count+notspam_word_count)\n",
    "    elif label==1:\n",
    "        return (spam_dic[word]+1)/(word_count+spam_word_count)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prob(label, comment):\n",
    "    words = str(comment).split()\n",
    "    class_prob = spam_prob if label == 1 else NotSpam_prob\n",
    "#   a postrior probability (text|label)\n",
    "    result = class_prob\n",
    "    for word in words:\n",
    "        if (cond_probs[word]):\n",
    "            result *= cond_probs[word][label]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileAddress='./resources/stopwords-fa.txt'\n",
    "with open(fileAddress,encoding='utf-8') as file:\n",
    "    sw=file.read().splitlines()\n",
    "del sw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PersianStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('./train.csv')\n",
    "test= pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(' ',inplace=True)\n",
    "data['comment'] = data['title'] +\" \"+ data['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['comment'] = data['comment'].apply(remove_enter)\n",
    "data['comment'] = data['comment'].apply(remove_punctuation)\n",
    "data['comment'] = data['comment'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    data.at[i, 'comment'] = stemmingText(str(data.at[i,'comment']).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['comment','verification_status']]\n",
    "data['tokens'] = data['comment'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=defaultdict(int)\n",
    "for comment in data['comment'].values:\n",
    "    for elem in comment.split(' '):\n",
    "            words[elem]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = len(words)\n",
    "\n",
    "spam_prob = data[data['verification_status']==1].shape[0]/data.shape[0]\n",
    "NotSpam_prob = 1-spam_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = data[data['verification_status']==1]\n",
    "nspam_df = data[data['verification_status']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dic=defaultdict(int)\n",
    "for comment in spam_df['comment'].values:\n",
    "    for elem in comment.split(' '):\n",
    "            spam_dic[elem]+=1\n",
    "\n",
    "not_spam_dic=defaultdict(int)\n",
    "for comment in nspam_df['comment'].values:\n",
    "    for elem in comment.split(' '):\n",
    "            not_spam_dic[elem]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of total words in not spam with repeats\n",
    "notspam_word_count=0\n",
    "for key in not_spam_dic.keys():\n",
    "    notspam_word_count += not_spam_dic[key]\n",
    "\n",
    "#number of total words in not spam with repeats\n",
    "spam_word_count=0\n",
    "for key in spam_dic.keys():\n",
    "    spam_word_count += spam_dic[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditional probabilities\n",
    "cond_probs=defaultdict(int)\n",
    "for word in words.keys():\n",
    "    cond_probs[word] = (cond_prob(word,0), cond_prob(word,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text']= test['title']+ ' ' + test['comment']\n",
    "test['text'] = test['text'].apply(remove_punctuation)\n",
    "for i in range(test.shape[0]):\n",
    "    test.at[i, 'comment'] = stemmingText(str(test.at[i,'comment']).split())\n",
    "\n",
    "verification_status=[]\n",
    "for i in range(test.shape[0]):\n",
    "    if str(test.loc[i].title)==str(test.loc[i].comment):\n",
    "        verification_status.append(1)\n",
    "    else:\n",
    "        if prob(0, test.loc[i].text) < prob(1, test.loc[i].text):\n",
    "            verification_status.append(1)\n",
    "        else:\n",
    "            verification_status.append(0)\n",
    "df = pd.DataFrame(list(zip(test['id'].values, verification_status)), columns =['id', 'verification_status'])\n",
    "df.to_csv(r'./ans.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
